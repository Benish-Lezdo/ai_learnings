{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benish-Lezdo/ai_learnings/blob/main/colpoli_document_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ColPali Example\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "sGXhK9ZBpuxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade byaldi\n",
        "!pip install  poppler-utils\n",
        "!pip install -q pdf2image git+https://github.com/huggingface/transformers.git qwen-vl-utils flash-attn\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aABp4Vhbp4EC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "37qUBCaOds_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -q pdf2image\n",
        "!pip install flash-attn\n",
        "\n",
        "!sudo apt-get install -y poppler-utils\n",
        "\n",
        "from byaldi import RAGMultiModalModel\n",
        "from huggingface_hub import notebook_login\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "images = convert_from_path(\"/content/pdf/injury_report.pdf\")\n",
        "images[0]"
      ],
      "metadata": {
        "id": "5H9UwaUudr7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from byaldi import RAGMultiModalModel\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from torch.quantization import quantize_dynamic\n",
        "\n",
        "# !wget https://arxiv.org/pdf/1706.03762\n",
        "# !mkdir docs\n",
        "# !mv 1706.03762 docs/attention.pdf\n",
        "# !cp -r docs/attention.pdf docs/attention_with_a_mustache.pdf\n",
        "\n",
        "# model = RAGMultiModalModel.from_pretrained(\"vidore/colpali\")\n",
        "model = RAGMultiModalModel.from_pretrained(\"vidore/colpali-v1.2\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "index_name = \"image_index\"\n",
        "\n",
        "model.index(\n",
        "    input_path=Path(\"/content/pdf\"),\n",
        "    index_name= index_name,\n",
        "    store_collection_with_index=False,\n",
        "    overwrite=True,\n",
        ")"
      ],
      "metadata": {
        "id": "OQzyfbRF7sx_",
        "outputId": "67487b0f-16c9-44ff-e431-3c2694d8d202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477,
          "referenced_widgets": [
            "ff850acf59834223bda0fee009276965",
            "3e5c4ec73f05414cb5b023708e20d7ad",
            "9a7c528caf814f2fb4741b0479f81cf5",
            "ffe226bdb82c4d80b6f4ecec0a38db0c",
            "79899167bd1a4cdba7aaf9a9af06520e",
            "beaf8fa8a874437fbb62a988aa1b8ece",
            "7cf9465529244a01981bdeb7d72da02e",
            "b5c55f8b33c6400ea9a68c9e7cebb59e",
            "e17ef05264804bdaaa74043a92005785",
            "2d2ae718bd9841889b3f42eac4778133",
            "7df5ababdaf241c386bc346d03144247"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verbosity is set to 1 (active). Pass verbose=0 to make quieter.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff850acf59834223bda0fee009276965"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indexing file: /content/pdf/injury_report.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are passing both `text` and `images` to `PaliGemmaProcessor`. The processor expects special image tokens in the text, as many tokens as there are images per each text. It is recommended to add `<image>` tokens in the very beginning of your text and `<bos>` token after that. For this call, we will infer how many images each text has and add special tokens.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Input type (torch.FloatTensor) and weight type (CPUBFloat16Type) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-074a68ff86d5>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mindex_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"image_index\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m model.index(\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0minput_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mindex_name\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mindex_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/byaldi/RAGModel.py\u001b[0m in \u001b[0;36mindex\u001b[0;34m(self, input_path, index_name, doc_ids, store_collection_with_index, overwrite, metadata, max_image_width, max_image_height, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \"\"\"\n\u001b[0;32m--> 124\u001b[0;31m         return self.model.index(\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mindex_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/byaldi/colpali.py\u001b[0m in \u001b[0;36mindex\u001b[0;34m(self, input_path, index_name, doc_ids, store_collection_with_index, overwrite, metadata, max_image_width, max_image_height)\u001b[0m\n\u001b[1;32m    362\u001b[0m                 \u001b[0mdoc_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdoc_ids\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhighest_doc_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m                 \u001b[0mdoc_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                 self.add_to_index(\n\u001b[0m\u001b[1;32m    365\u001b[0m                     \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                     \u001b[0mstore_collection_with_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/byaldi/colpali.py\u001b[0m in \u001b[0;36madd_to_index\u001b[0;34m(self, input_item, store_collection_with_index, doc_id, metadata)\u001b[0m\n\u001b[1;32m    446\u001b[0m                     )\n\u001b[1;32m    447\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m                     self._process_and_add_to_index(\n\u001b[0m\u001b[1;32m    449\u001b[0m                         \u001b[0mitem_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                         \u001b[0mstore_collection_with_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/byaldi/colpali.py\u001b[0m in \u001b[0;36m_process_and_add_to_index\u001b[0;34m(self, item, store_collection_with_index, doc_id, metadata)\u001b[0m\n\u001b[1;32m    498\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m                         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m                         self._add_to_index(\n\u001b[0m\u001b[1;32m    501\u001b[0m                             \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m                             \u001b[0mstore_collection_with_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/byaldi/colpali.py\u001b[0m in \u001b[0;36m_add_to_index\u001b[0;34m(self, image, store_collection_with_index, doc_id, page_id, metadata)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mprocessed_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessed_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mprocessed_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# Add to index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/colpali_engine/models/paligemma/colpali/modeling_colpali.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/paligemma/modeling_paligemma.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, pixel_values, attention_mask, position_ids, past_key_values, token_type_ids, cache_position, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;31m# Merge text and images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpixel_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mimage_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_image_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0mspecial_image_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_token_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/paligemma/modeling_paligemma.py\u001b[0m in \u001b[0;36mget_image_features\u001b[0;34m(self, pixel_values)\u001b[0m\n\u001b[1;32m    403\u001b[0m             image_features (`torch.Tensor`): Image feature tensor of shape `(num_images, image_length, embed_dim)`).\n\u001b[1;32m    404\u001b[0m         \"\"\"\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0mimage_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision_tower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0mselected_image_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0mimage_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_modal_projector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_image_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/siglip/modeling_siglip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict, interpolate_pos_encoding)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m         return self.vision_model(\n\u001b[0m\u001b[1;32m   1191\u001b[0m             \u001b[0mpixel_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/siglip/modeling_siglip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict, interpolate_pos_encoding)\u001b[0m\n\u001b[1;32m   1087\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolate_pos_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolate_pos_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/siglip/modeling_siglip.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, pixel_values, interpolate_pos_encoding)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixel_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolate_pos_encoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpixel_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0mpatch_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixel_values\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape = [*, width, grid, grid]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatch_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 454\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    455\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (CPUBFloat16Type) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Load the BioBERT tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
        "model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
        "\n",
        "# Function to embed a chunk of text\n",
        "def embed_text(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # Extract the [CLS] token embedding as a representation of the text\n",
        "\n",
        "    print(outputs, \"kkkkkkkkk\")\n",
        "    embeddings = outputs.last_hidden_state[:, 0, :]\n",
        "    return embeddings\n",
        "\n",
        "# Function to split a document into sentences\n",
        "def split_into_sentences(document):\n",
        "    # Assuming the document is a string of text, split by periods or newlines.\n",
        "    sentences = document.split('. ')\n",
        "    return sentences\n",
        "\n",
        "# Function to answer a query from a document\n",
        "def answer_query(document, query):\n",
        "    # Step 1: Split the document into sentences or chunks\n",
        "    chunks = split_into_sentences(document)\n",
        "\n",
        "    # Step 2: Embed the query\n",
        "    query_embedding = embed_text(query)\n",
        "\n",
        "    # Step 3: Embed each chunk of the document\n",
        "    chunk_embeddings = [embed_text(chunk) for chunk in chunks]\n",
        "\n",
        "    # Step 4: Calculate similarity between the query and each chunk\n",
        "    similarities = [F.cosine_similarity(chunk_embedding, query_embedding, dim=1) for chunk_embedding in chunk_embeddings]\n",
        "\n",
        "    # Step 5: Find the most similar chunk (highest similarity score)\n",
        "    most_similar_chunk_idx = torch.argmax(torch.cat(similarities))\n",
        "\n",
        "    # Step 6: Return the most relevant chunk of the document as the answer\n",
        "    return chunks[most_similar_chunk_idx]\n",
        "\n",
        "# Example usage\n",
        "document = \"\"\"\n",
        "Cardiovascular disease is the leading cause of death worldwide. It affects millions of people every year.\n",
        "There are several types of cardiovascular diseases, including coronary artery disease and heart failure.\n",
        "Prevention includes lifestyle changes, such as regular exercise and a healthy diet.\n",
        "\"\"\"\n",
        "\n",
        "query = \"What is the leading cause of death?\"\n",
        "\n",
        "# Get the most relevant sentence or chunk from the document\n",
        "answer = answer_query(document, query)\n",
        "print(f\"Answer: {answer}\")\n"
      ],
      "metadata": {
        "id": "T_P6M-g_y-2q",
        "outputId": "44e7fed3-8702-4e88-f3ca-d89756d80265",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.3766,  0.1432, -0.3651,  ..., -0.1829, -0.0042, -0.5757],\n",
            "         [ 0.0701, -0.1438, -0.1996,  ...,  0.0226, -0.8468, -0.3335],\n",
            "         [ 0.1158,  0.3318, -0.1784,  ...,  0.2432,  0.2813, -0.3980],\n",
            "         ...,\n",
            "         [-0.3711, -0.0717, -0.2687,  ...,  0.1181, -0.1134, -0.4047],\n",
            "         [ 0.3919, -0.1858, -0.0445,  ...,  0.1552, -0.4503, -0.4781],\n",
            "         [-0.2654,  0.2086, -0.6569,  ..., -0.0192, -0.2300, -0.9680]]]), pooler_output=tensor([[ 9.5044e-02, -3.5819e-02,  9.8310e-01, -1.0000e+00,  1.0000e+00,\n",
            "          2.0829e-01, -6.9803e-02,  9.5632e-01, -1.1651e-01, -1.0391e-01,\n",
            "          9.2999e-01,  9.9997e-01,  5.2889e-01, -9.2617e-01,  4.7640e-03,\n",
            "          1.4112e-01,  1.0000e+00,  1.1433e-02, -9.9923e-01, -1.9318e-01,\n",
            "         -1.1282e-01, -9.7692e-01, -2.0027e-01,  9.8232e-01,  3.2518e-02,\n",
            "          1.3087e-01,  9.9995e-01,  9.9910e-01, -1.4612e-01,  8.3667e-02,\n",
            "          3.6302e-02, -1.0000e+00,  9.9680e-01, -9.9998e-01, -4.3749e-02,\n",
            "         -1.8958e-02,  6.5543e-02,  4.0602e-02,  9.5383e-01, -9.9445e-01,\n",
            "          8.7088e-02, -8.8206e-01, -1.4429e-02,  1.4723e-01,  9.9476e-01,\n",
            "         -9.1032e-02, -1.6105e-01, -2.4683e-02,  2.0651e-01,  7.4217e-01,\n",
            "          3.8566e-02,  9.9752e-01,  8.8551e-01,  9.9921e-01,  9.9994e-01,\n",
            "          7.1579e-02,  1.0000e+00, -2.0858e-01,  9.7124e-01, -2.0040e-02,\n",
            "          1.0000e+00,  7.9046e-02,  1.8421e-02, -1.2073e-01,  1.0279e-01,\n",
            "          9.9231e-02, -8.6736e-01,  2.4425e-02,  3.4435e-02,  3.2344e-02,\n",
            "         -2.2404e-01, -7.7916e-02,  9.9915e-01, -9.9994e-01, -2.4465e-02,\n",
            "          8.4458e-02, -5.9912e-02, -9.7712e-01,  9.9977e-01,  9.9996e-01,\n",
            "         -1.2883e-01, -9.9956e-01,  1.0000e+00, -8.5713e-02, -4.5537e-02,\n",
            "          5.9730e-02,  9.1587e-01, -9.9997e-01,  5.9825e-02,  1.6564e-01,\n",
            "          6.9039e-01, -9.9996e-01,  1.9904e-02, -7.0292e-01,  9.9902e-01,\n",
            "          4.7031e-01,  1.8415e-01, -9.2912e-02,  4.3863e-01, -1.4881e-01,\n",
            "          1.1013e-01,  9.8588e-01, -6.3152e-01,  8.8335e-01, -6.4622e-01,\n",
            "          1.4153e-01, -9.8135e-02, -1.3123e-02, -1.1315e-01, -1.8341e-01,\n",
            "          4.3591e-02,  5.0629e-02, -8.9876e-03, -1.2556e-01,  9.8780e-01,\n",
            "          8.3716e-01,  1.0000e+00,  9.2750e-01,  2.8077e-02,  9.9936e-01,\n",
            "         -3.8852e-02,  9.7110e-01,  9.9995e-01, -6.8460e-02,  5.8085e-02,\n",
            "          3.3678e-03,  5.1334e-02,  9.9806e-01,  1.6686e-01, -7.5513e-02,\n",
            "         -1.0523e-01, -9.9997e-01, -9.9383e-01,  9.9956e-01, -1.4382e-02,\n",
            "          9.9997e-01, -9.9996e-01,  5.2512e-01, -9.7887e-01, -1.5464e-01,\n",
            "         -7.0738e-01,  5.6326e-02, -9.5908e-01, -8.2958e-03,  9.9989e-01,\n",
            "         -7.8457e-03, -9.9716e-01, -6.9205e-02,  4.7907e-02, -2.1519e-01,\n",
            "          8.0882e-02, -1.4365e-01,  3.3606e-02,  9.9902e-01,  6.1113e-01,\n",
            "          9.9265e-01,  9.9591e-01, -9.0937e-02, -3.8933e-02,  8.3793e-01,\n",
            "         -1.4100e-01, -9.9982e-01, -4.5590e-02, -9.9331e-01,  9.9684e-01,\n",
            "          9.9993e-01,  2.8818e-01,  9.6518e-01,  9.9995e-01,  4.2423e-03,\n",
            "         -2.3097e-02, -3.5881e-02,  9.9013e-02,  8.9884e-01, -9.2204e-03,\n",
            "         -1.6331e-01, -1.2671e-01, -4.1241e-02, -9.9996e-01, -3.7435e-02,\n",
            "          9.4735e-01,  1.5387e-01,  2.3501e-02, -9.6616e-01, -1.0000e+00,\n",
            "          7.4528e-03, -9.9971e-01,  5.1396e-03, -1.7701e-02,  1.1147e-01,\n",
            "          1.6521e-01,  9.9985e-01, -9.3299e-01, -4.4872e-02,  2.8247e-02,\n",
            "          2.2155e-01,  9.9908e-01,  3.8797e-03,  9.9988e-01, -3.2631e-02,\n",
            "         -9.9999e-01, -9.5410e-01, -4.8098e-01, -2.2805e-01,  1.6257e-01,\n",
            "         -3.4222e-02, -6.9493e-02, -1.9714e-01, -8.3648e-01, -9.9777e-01,\n",
            "         -9.7366e-01,  3.5590e-02,  2.8769e-02, -3.0813e-02, -2.5917e-02,\n",
            "         -3.0798e-01,  1.0020e-01, -3.1904e-02, -1.1584e-01,  9.9974e-01,\n",
            "         -9.9998e-01,  9.0631e-02, -4.6983e-04, -9.9999e-01, -1.0000e+00,\n",
            "          1.0424e-01, -6.7267e-02, -6.1809e-02,  6.1797e-03, -7.7091e-01,\n",
            "          7.8683e-02,  9.5141e-01,  1.0000e+00, -7.8440e-02, -8.4607e-03,\n",
            "         -9.9962e-01,  9.1524e-01,  1.4443e-01,  1.3597e-01, -2.3583e-02,\n",
            "          1.0266e-01,  2.6893e-01,  1.0921e-02, -7.4762e-01,  1.1983e-02,\n",
            "         -1.4524e-02, -8.3085e-01,  4.5059e-02,  1.1422e-01,  2.5749e-01,\n",
            "         -1.1885e-01,  4.3470e-01, -5.4828e-02,  9.9999e-01, -9.9216e-01,\n",
            "          2.4863e-01,  9.8535e-01, -9.9995e-01,  8.8587e-02,  8.8423e-01,\n",
            "          5.3392e-02, -9.9830e-01,  1.1864e-01, -2.0741e-01, -5.5299e-02,\n",
            "         -1.7672e-02,  9.9998e-01,  4.8592e-02,  6.6588e-02,  3.3921e-02,\n",
            "         -9.9911e-01, -1.1726e-01, -8.0145e-02,  9.9999e-01,  8.5955e-01,\n",
            "          2.2005e-03, -2.3067e-02,  4.9453e-01, -1.0000e+00, -9.5102e-01,\n",
            "          1.8973e-01,  9.8810e-01, -1.0000e+00,  1.7978e-02,  9.9982e-01,\n",
            "          9.9350e-01, -3.7278e-02, -9.9983e-01,  1.6727e-01, -9.9997e-01,\n",
            "          9.9503e-02,  8.1420e-02,  5.6803e-02, -1.1292e-02, -8.4576e-02,\n",
            "          7.4340e-02,  9.9979e-01,  9.9913e-01,  3.0338e-02, -3.8046e-02,\n",
            "         -1.2030e-01, -1.0000e+00, -9.9682e-01, -1.2943e-01, -9.7810e-02,\n",
            "         -9.9505e-01,  1.0000e+00, -9.9656e-01,  9.9885e-01,  9.9287e-01,\n",
            "          9.4626e-01, -2.0846e-02, -1.9192e-02, -9.9330e-01,  2.5335e-03,\n",
            "          9.9797e-01,  9.9983e-01,  7.3240e-02, -1.1417e-01,  9.1246e-01,\n",
            "         -5.6878e-02,  6.9007e-03, -6.5716e-02, -1.0547e-01,  7.6339e-02,\n",
            "          3.0211e-02,  4.6019e-01,  1.4475e-01, -9.4669e-01, -1.1454e-02,\n",
            "         -2.2203e-01,  2.9113e-03, -7.9907e-01,  1.3670e-01, -1.8003e-02,\n",
            "         -4.5414e-02, -1.0662e-01, -7.8761e-02, -6.1791e-01,  2.7573e-02,\n",
            "         -2.4602e-02,  8.4083e-01, -7.8997e-03,  9.4569e-01,  7.0480e-02,\n",
            "         -9.9813e-01,  9.9983e-01, -1.7393e-02,  1.2480e-01,  9.7078e-01,\n",
            "          9.9734e-01, -9.9967e-01, -1.4135e-01,  2.5121e-02, -2.1478e-02,\n",
            "         -6.3694e-02,  1.0000e+00, -7.1556e-01, -4.8465e-02,  1.6588e-01,\n",
            "         -5.6876e-03, -8.5412e-02, -1.7927e-02,  2.8855e-01, -1.4112e-01,\n",
            "          9.0413e-01,  1.7700e-02,  9.9647e-01, -8.6611e-01, -2.4567e-02,\n",
            "          2.7834e-02, -3.2225e-01, -1.9260e-01,  6.2514e-02, -8.0963e-01,\n",
            "          4.4013e-04, -9.0194e-01, -1.3934e-02, -9.0353e-01, -3.8272e-02,\n",
            "          9.9763e-01,  7.2305e-02,  7.2011e-02,  4.0310e-01,  1.0729e-01,\n",
            "          9.9998e-01, -1.0000e+00,  1.6766e-02,  9.9996e-01, -9.7430e-02,\n",
            "         -7.5943e-02,  1.5225e-01, -9.4027e-01,  2.7032e-01,  1.6286e-02,\n",
            "         -9.9910e-01, -4.6351e-02,  2.6136e-02, -1.5940e-01,  5.8400e-02,\n",
            "          5.7834e-02, -7.7801e-02,  6.2646e-01,  7.0809e-02, -5.5391e-02,\n",
            "          1.7359e-01,  1.1420e-01,  6.8874e-02, -2.3274e-03,  7.1843e-02,\n",
            "         -1.9682e-01, -4.9282e-02,  3.1776e-02,  1.1540e-02,  3.6076e-02,\n",
            "          9.9262e-01,  7.9574e-02, -9.9978e-01,  9.7291e-01, -1.3703e-01,\n",
            "         -9.9355e-01, -2.9074e-03, -9.9949e-01,  1.0000e+00,  9.9249e-01,\n",
            "          8.8990e-01,  9.4432e-01, -9.9969e-01, -9.9854e-01,  4.8254e-01,\n",
            "         -1.2983e-02,  5.8031e-02,  1.6023e-01,  9.3290e-01, -1.1754e-02,\n",
            "         -2.1945e-02,  2.2898e-02, -1.8946e-02,  7.5291e-03,  9.5741e-01,\n",
            "          5.7474e-01, -9.9988e-01, -3.4259e-02,  7.2574e-01,  8.9592e-01,\n",
            "         -8.6382e-01, -9.1451e-02,  6.7129e-01,  1.2623e-01, -4.6299e-02,\n",
            "         -1.5669e-01,  7.3864e-03,  8.4289e-02, -9.8114e-01, -5.7253e-02,\n",
            "         -1.3783e-01,  3.1392e-02, -7.0451e-02, -2.8459e-02,  9.1973e-01,\n",
            "         -9.3257e-01, -1.2804e-01,  1.0401e-01, -5.8973e-02, -7.7372e-01,\n",
            "         -9.5810e-01, -8.2978e-01, -9.4192e-01,  1.9269e-01,  7.4653e-03,\n",
            "         -9.9944e-01,  7.9211e-02,  9.1443e-01,  9.9571e-01,  9.9977e-01,\n",
            "         -2.9879e-02, -9.5045e-02,  1.3258e-01, -1.4212e-01, -9.9954e-01,\n",
            "         -1.0176e-01,  1.0323e-01, -7.5414e-02, -6.9982e-01, -3.0640e-02,\n",
            "          6.6399e-02,  6.6713e-01, -9.9766e-01,  9.9216e-01, -1.1829e-01,\n",
            "         -1.0478e-01,  8.9521e-02, -8.0636e-02, -1.2332e-01,  9.4676e-03,\n",
            "         -9.9992e-01,  4.3395e-02,  1.0000e+00,  9.8900e-01,  9.9356e-01,\n",
            "          5.1553e-01, -9.1194e-01, -5.1778e-02,  7.3583e-02, -9.9486e-01,\n",
            "         -9.9705e-01,  6.5606e-02, -3.2983e-02, -9.9992e-01,  9.8634e-01,\n",
            "         -9.9686e-01,  3.9796e-02,  1.1938e-01,  9.9401e-01,  9.9986e-01,\n",
            "         -1.1543e-01, -9.9980e-01, -9.9991e-01, -7.4292e-01,  1.3419e-01,\n",
            "         -1.3974e-01,  7.1064e-02, -1.7493e-01, -9.6312e-03, -1.0564e-01,\n",
            "          9.8168e-01,  5.9967e-02,  1.5614e-01,  7.6912e-01,  9.9998e-01,\n",
            "         -3.4515e-02, -9.9806e-01, -3.9029e-01,  1.2654e-01, -5.5362e-01,\n",
            "         -1.1129e-01,  9.9863e-01, -2.6512e-02,  9.3964e-01,  9.9870e-01,\n",
            "         -9.9952e-01,  9.9299e-01, -9.9989e-01,  8.9960e-01,  9.9965e-01,\n",
            "         -1.0000e+00, -1.4336e-01, -1.0000e+00, -5.5700e-01,  1.1305e-02,\n",
            "          2.1551e-01, -1.0191e-01,  9.2896e-01, -1.0000e+00, -9.9994e-01,\n",
            "         -2.0028e-01, -1.9000e-01, -9.4186e-01,  6.3015e-01, -7.5210e-02,\n",
            "         -1.5117e-01, -5.5604e-02,  1.2405e-01,  1.7451e-01, -8.3793e-01,\n",
            "          9.9968e-01, -1.2891e-01,  9.0321e-03, -1.0000e+00,  9.9937e-01,\n",
            "         -7.4250e-02,  2.3187e-02,  1.0000e+00,  6.3417e-03,  8.2682e-02,\n",
            "          1.6459e-02, -1.0000e+00,  8.4803e-02,  1.0897e-01, -9.7211e-01,\n",
            "          8.8942e-01,  2.7766e-02, -7.4344e-02, -2.4484e-03, -9.9936e-02,\n",
            "         -9.9254e-01, -1.5351e-01, -9.9999e-01,  1.0000e+00, -8.9742e-01,\n",
            "         -2.0220e-01,  2.2563e-01, -3.1313e-02,  1.2128e-02,  9.9178e-01,\n",
            "          1.0000e+00, -9.9936e-01,  2.7976e-02,  1.0000e+00, -1.4692e-01,\n",
            "          9.0887e-02, -9.9999e-01, -4.4900e-02, -6.2114e-01,  1.6862e-01,\n",
            "          1.0000e+00, -1.8859e-01, -8.7955e-02,  9.9988e-01, -1.0000e+00,\n",
            "         -8.6621e-01, -1.8409e-02, -1.8740e-03,  6.3010e-02, -1.0000e+00,\n",
            "         -1.4577e-01, -9.6490e-01, -1.3338e-01, -1.0000e+00,  9.6323e-01,\n",
            "         -1.0000e+00,  3.2072e-02,  9.9997e-01,  5.5132e-01,  9.9972e-01,\n",
            "         -4.5846e-02,  4.9138e-02,  1.6052e-01, -9.9998e-01,  7.8988e-01,\n",
            "         -2.3974e-01,  1.6294e-01, -9.7697e-01, -9.6918e-01, -1.7208e-01,\n",
            "          8.1926e-01, -9.8137e-01, -7.0806e-02, -7.0989e-01, -1.2925e-01,\n",
            "          1.7879e-02, -4.3742e-02,  8.2578e-03, -4.8278e-01,  1.4986e-01,\n",
            "         -2.8464e-01,  2.3409e-01,  2.0380e-01, -8.7590e-02, -2.9301e-02,\n",
            "          9.9570e-01, -1.0000e+00,  9.1526e-02, -9.9992e-01,  2.1365e-02,\n",
            "          1.2521e-01, -1.8911e-01, -1.5151e-01, -1.7323e-01,  8.4071e-02,\n",
            "         -9.9749e-01,  1.0000e+00, -9.9999e-01, -9.9999e-01,  9.9998e-01,\n",
            "         -7.4055e-02, -9.4048e-01,  1.8710e-01,  2.4672e-01,  2.9712e-01,\n",
            "          1.5998e-01,  1.2255e-01,  2.1750e-01,  1.2101e-01, -9.9588e-01,\n",
            "          8.6573e-01,  1.7447e-01,  6.4086e-02,  8.7979e-02, -1.4051e-01,\n",
            "         -9.9679e-01,  1.0000e+00,  1.0000e+00,  9.9852e-01, -9.9994e-01,\n",
            "         -1.8628e-02, -1.1775e-02,  9.9999e-01,  2.3942e-01,  2.4474e-02,\n",
            "          9.8524e-01,  9.8942e-01, -4.4117e-02, -7.4147e-01,  1.6233e-01,\n",
            "          1.0120e-01,  8.5512e-03,  1.7695e-01, -9.7349e-01, -9.9732e-01,\n",
            "          1.0393e-01, -9.9959e-01, -9.8789e-01,  9.8638e-01,  1.2421e-01,\n",
            "          1.0000e+00,  6.8135e-03,  1.4188e-01,  7.3321e-03, -7.0596e-01,\n",
            "         -9.9572e-01, -1.0321e-01, -9.9561e-01, -4.4424e-03, -9.9995e-01,\n",
            "         -1.0000e+00, -1.9382e-01,  1.4190e-01, -9.9618e-01, -4.6376e-02,\n",
            "          4.6851e-02, -9.9466e-01, -8.5636e-01, -9.9825e-01,  3.6549e-01,\n",
            "         -8.6491e-01, -9.7611e-01, -9.5471e-02,  4.1801e-01,  3.9319e-02,\n",
            "          1.9784e-02, -3.6213e-01,  3.6589e-01,  7.6354e-01,  7.9026e-03,\n",
            "         -7.8205e-02,  1.1489e-01, -9.9451e-01, -1.1002e-01, -1.0000e+00,\n",
            "          9.9344e-01, -1.0000e+00,  1.1675e-01,  9.9999e-01,  1.0000e+00,\n",
            "          2.0862e-02, -9.9998e-01,  9.9447e-01,  4.7094e-02,  1.0000e+00,\n",
            "          6.8457e-02, -9.9913e-01, -9.9998e-01,  1.1193e-02,  8.3318e-02,\n",
            "          1.0000e+00,  1.2820e-01,  9.6171e-01, -4.6872e-02, -1.4984e-01,\n",
            "          8.3152e-02, -5.7922e-02, -1.6346e-01, -1.8316e-01,  6.0166e-02,\n",
            "          9.9323e-01,  1.3022e-01,  1.0000e+00]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None) kkkkkkkkk\n",
            "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.2562,  0.3576, -0.4342,  ...,  0.1335,  0.2188, -0.5163],\n",
            "         [-0.2568,  0.3381, -0.2964,  ...,  0.1004, -0.0608, -0.2208],\n",
            "         [ 0.1761,  0.5085, -0.0440,  ...,  0.0682,  0.3868, -0.3084],\n",
            "         ...,\n",
            "         [-0.4378,  0.2817, -0.4436,  ...,  0.1386,  0.2780, -0.5382],\n",
            "         [-0.4161,  0.1600, -0.4028,  ...,  0.1552,  0.0280, -0.4918],\n",
            "         [-0.0087,  0.5959, -0.5669,  ..., -0.6455,  0.5498, -1.7858]]]), pooler_output=tensor([[ 3.1557e-02,  6.0582e-03,  8.8145e-01, -1.0000e+00,  9.9999e-01,\n",
            "          3.3806e-01,  1.2030e-02,  8.1954e-01, -1.4634e-01, -7.2891e-02,\n",
            "          6.5668e-01,  9.9920e-01, -5.9314e-01, -6.4821e-01,  8.2836e-03,\n",
            "          1.6105e-01,  9.9999e-01, -1.8702e-01, -9.8389e-01, -2.6724e-01,\n",
            "         -9.4195e-02, -7.7562e-01, -8.9229e-02,  9.9767e-01, -7.1164e-03,\n",
            "          8.0666e-02,  9.9900e-01,  9.8126e-01, -5.1513e-02,  1.0968e-02,\n",
            "         -8.4716e-02, -9.9999e-01,  9.9960e-01, -9.9963e-01, -1.4237e-01,\n",
            "          2.0321e-02, -8.3587e-02,  5.5762e-02,  9.8092e-01, -9.9958e-01,\n",
            "         -1.0636e-02, -9.8470e-01, -2.8957e-02,  5.1465e-03,  9.9968e-01,\n",
            "         -1.7913e-02,  1.4849e-01,  8.5437e-02,  1.1558e-01, -1.3917e-01,\n",
            "          2.2586e-01,  7.9103e-01, -3.9352e-02,  9.7978e-01,  9.9790e-01,\n",
            "          5.1540e-02,  9.9999e-01, -1.6340e-01,  5.5315e-01,  1.8223e-01,\n",
            "          9.9999e-01,  1.1861e-02,  1.2679e-01,  1.5649e-02,  1.0109e-01,\n",
            "          8.4557e-02, -9.4546e-01,  1.0479e-02,  9.5011e-02,  5.9392e-02,\n",
            "         -1.7685e-01,  6.1623e-04,  9.9265e-01, -9.9912e-01, -5.3465e-02,\n",
            "         -5.6424e-02, -1.3107e-01, -6.9314e-01,  9.9705e-01,  9.9891e-01,\n",
            "         -1.2986e-01, -9.9014e-01,  9.9999e-01, -6.2370e-02, -1.3695e-01,\n",
            "          8.7917e-02, -1.5627e-01, -9.9880e-01, -7.3364e-02, -6.2219e-02,\n",
            "          9.5445e-01, -9.9956e-01,  4.3221e-02, -9.4001e-01,  9.8637e-01,\n",
            "         -4.7872e-01,  2.2337e-01, -9.3470e-02,  8.5411e-01, -2.0105e-01,\n",
            "          1.0856e-01,  9.9888e-01,  6.2187e-01,  1.9294e-01,  7.4257e-01,\n",
            "          1.4197e-01, -8.5789e-02, -7.1299e-02, -1.8790e-01, -1.4631e-01,\n",
            "          8.9570e-02,  3.4945e-02, -1.9787e-01, -1.0784e-02,  9.9839e-01,\n",
            "         -1.4339e-01,  9.9998e-01,  9.9592e-01,  8.7685e-02,  9.8627e-01,\n",
            "         -1.4989e-01,  9.9866e-01,  9.9869e-01,  9.0693e-02, -8.1513e-02,\n",
            "         -6.9908e-02, -1.2669e-01,  9.9983e-01,  2.0397e-01, -8.7983e-02,\n",
            "         -4.2219e-02, -9.9927e-01, -9.9954e-01,  9.8984e-01, -5.6169e-02,\n",
            "          9.9903e-01, -9.9853e-01,  9.6669e-01, -8.2513e-01,  1.7069e-02,\n",
            "         -9.8432e-01,  7.0211e-02, -9.9719e-01, -9.6543e-02,  9.9884e-01,\n",
            "         -1.3463e-01, -9.9987e-01, -2.0963e-01,  6.4546e-02, -3.6118e-01,\n",
            "         -1.2446e-02,  6.3914e-02, -9.6758e-02,  9.3317e-01,  9.5972e-01,\n",
            "          9.9913e-01,  9.9983e-01,  1.3455e-02,  2.2237e-02,  9.8332e-01,\n",
            "         -8.9027e-02, -9.9666e-01,  3.0398e-02, -9.9955e-01,  9.6828e-01,\n",
            "          9.9933e-01,  3.0713e-01,  5.8381e-01,  9.9743e-01, -3.4414e-02,\n",
            "         -1.0064e-01,  7.1057e-02,  8.8173e-02, -5.4017e-01,  1.2253e-01,\n",
            "         -6.5130e-03, -2.3636e-02,  5.5541e-02, -9.9866e-01,  5.1767e-02,\n",
            "         -2.7173e-01,  1.1124e-01,  2.4363e-02, -2.6832e-01, -9.9997e-01,\n",
            "         -1.3154e-01, -9.9313e-01,  9.0797e-02, -5.6449e-02,  1.1342e-02,\n",
            "          1.5641e-01,  9.9889e-01,  1.2721e-01, -2.9462e-02, -2.1718e-02,\n",
            "          2.5954e-01,  9.8433e-01, -9.7541e-02,  9.9704e-01, -4.1424e-02,\n",
            "         -9.9984e-01, -9.9691e-01,  8.8567e-01, -3.4876e-01,  9.6672e-02,\n",
            "         -1.8628e-01, -4.1665e-02, -1.7901e-01,  4.1839e-01, -8.3582e-01,\n",
            "          1.3367e-02, -7.0859e-02, -3.6553e-02, -2.1383e-02,  8.7467e-02,\n",
            "         -2.3989e-01,  2.0081e-01, -1.5883e-01, -1.4244e-01,  9.9142e-01,\n",
            "         -9.9931e-01,  2.1429e-02, -1.0885e-01, -9.9969e-01, -9.9991e-01,\n",
            "          5.2186e-02, -1.6717e-01, -5.8527e-01, -4.2430e-02, -5.7367e-01,\n",
            "          7.9871e-02,  9.9121e-01,  1.0000e+00,  3.9281e-02, -2.2565e-02,\n",
            "         -9.9034e-01,  4.3941e-01,  4.1173e-02, -1.1093e-01,  1.1882e-01,\n",
            "          4.4711e-02,  1.9934e-01, -8.7859e-02, -9.8392e-01, -8.5416e-02,\n",
            "          3.3909e-02, -9.3660e-01, -4.7906e-02,  7.2759e-02, -9.2764e-01,\n",
            "         -6.1496e-03, -3.3619e-01, -1.0064e-01,  9.9982e-01, -9.9951e-01,\n",
            "          9.3497e-01,  9.1863e-01, -9.9947e-01,  2.6661e-01, -4.6108e-01,\n",
            "          5.2214e-02, -9.3818e-01,  1.0184e-01, -1.5160e-01, -1.3008e-01,\n",
            "         -8.2384e-02,  9.9977e-01, -1.3901e-01, -6.4122e-02,  2.8295e-02,\n",
            "         -9.8059e-01, -8.7286e-02, -1.0908e-01,  9.9988e-01,  9.9625e-01,\n",
            "          5.2845e-02,  4.9109e-02,  1.0818e-01, -9.9999e-01, -6.6562e-01,\n",
            "          3.8250e-01,  5.4429e-01, -1.0000e+00,  4.7756e-02,  9.9528e-01,\n",
            "          6.9037e-01, -2.0273e-01, -9.9718e-01,  5.1738e-02, -9.9905e-01,\n",
            "          9.4488e-02, -5.3370e-02, -1.5032e-01, -2.6063e-02, -3.1502e-03,\n",
            "         -5.3167e-02,  9.9543e-01,  9.7925e-01, -3.9084e-02,  6.5675e-02,\n",
            "         -1.0043e-01, -9.9999e-01, -8.4223e-01, -1.4522e-01,  1.4936e-02,\n",
            "         -9.2474e-01,  9.9999e-01, -9.0109e-01,  9.0008e-01,  9.9965e-01,\n",
            "          5.2046e-01,  3.2571e-02,  2.5253e-02, -9.9966e-01, -9.5245e-02,\n",
            "          9.7652e-01,  9.9744e-01, -4.8215e-03, -4.5710e-02,  9.8682e-01,\n",
            "          5.4098e-03,  1.8057e-01, -1.4482e-01,  2.1122e-02,  5.1951e-02,\n",
            "          1.0527e-02,  9.6367e-01,  6.5185e-01, -6.9570e-01,  9.2470e-01,\n",
            "         -1.8827e-01,  8.0213e-03, -9.0950e-01,  1.2639e-02,  1.2711e-01,\n",
            "         -5.3925e-02, -5.1850e-02, -1.4712e-01,  8.0794e-01,  1.4168e-01,\n",
            "         -5.5406e-02, -5.4143e-01,  7.2805e-02,  9.7158e-01,  1.3006e-01,\n",
            "         -9.4689e-01,  9.9480e-01,  1.6762e-03, -1.7017e-01,  2.9667e-01,\n",
            "          9.5673e-01, -9.8725e-01, -2.2984e-01,  6.1903e-02, -2.8624e-02,\n",
            "         -6.7058e-03,  1.0000e+00,  2.8416e-01,  7.3759e-01,  2.7285e-01,\n",
            "         -1.9791e-02, -2.7318e-02, -5.9750e-02, -9.5849e-01, -3.1014e-01,\n",
            "         -3.2575e-01, -1.0328e-01,  9.8459e-01,  2.6231e-01,  9.0417e-03,\n",
            "          1.5042e-02, -9.1295e-01, -1.5823e-01, -1.4533e-01, -9.1908e-01,\n",
            "         -9.5416e-02, -9.8260e-01,  1.0961e-01,  3.4628e-01,  7.5194e-03,\n",
            "          9.9961e-01, -1.5945e-02, -1.8105e-02,  9.5818e-02,  1.2718e-01,\n",
            "          9.9957e-01, -9.9986e-01, -1.8508e-02,  9.9956e-01, -8.9752e-02,\n",
            "         -1.2016e-01,  6.6207e-02, -2.6628e-01,  1.3761e-01, -2.4141e-02,\n",
            "         -9.7068e-01, -1.1407e-01,  9.8609e-02,  3.1743e-02,  6.8679e-02,\n",
            "          1.7573e-02, -1.1071e-01,  9.7806e-01,  1.2410e-01, -8.5959e-02,\n",
            "          1.3738e-01,  3.5247e-02, -6.0711e-02, -7.5117e-02,  8.8922e-02,\n",
            "         -6.7965e-02, -4.9829e-02,  8.7877e-02,  8.7717e-02,  1.0007e-01,\n",
            "          9.1308e-01,  1.5487e-01, -9.9428e-01,  5.0631e-01, -1.1314e-01,\n",
            "         -9.7134e-01, -3.7363e-02, -9.8845e-01,  9.9999e-01,  9.9975e-01,\n",
            "         -4.1770e-01,  1.5190e-01, -9.9005e-01, -9.5822e-01,  7.4753e-01,\n",
            "          1.6293e-01,  3.3301e-02,  8.5755e-02, -2.0893e-01, -1.3444e-04,\n",
            "          2.1082e-01, -3.2308e-03,  9.0780e-04,  1.3607e-01,  6.2320e-01,\n",
            "          5.2552e-01, -9.9608e-01, -1.5297e-01,  9.7496e-01,  2.1927e-01,\n",
            "         -9.8473e-01, -1.7857e-02,  3.0465e-02,  8.4018e-02, -3.5782e-02,\n",
            "         -1.0974e-01, -5.1422e-02, -5.6451e-02, -8.6452e-01,  4.5014e-03,\n",
            "         -1.3703e-01, -1.1739e-02, -2.5030e-01, -3.2806e-02,  5.4903e-01,\n",
            "         -4.1987e-01, -2.5522e-02, -1.0425e-01, -1.4750e-01,  8.3173e-01,\n",
            "         -9.9696e-01, -8.9490e-01, -6.4191e-01, -2.7150e-02, -1.3497e-02,\n",
            "         -9.9491e-01,  5.0350e-02,  9.9668e-01,  9.0350e-01,  9.9406e-01,\n",
            "         -5.0269e-02, -6.5402e-02,  2.3366e-01, -1.8328e-01, -9.9306e-01,\n",
            "         -5.9548e-02,  2.5378e-01, -1.2711e-01, -7.8533e-01,  8.8815e-02,\n",
            "          1.0759e-01, -2.3469e-01, -9.9985e-01,  9.9929e-01, -1.0471e-01,\n",
            "         -1.1673e-01,  3.6893e-02, -8.7318e-02,  1.4902e-03,  1.4716e-01,\n",
            "         -9.9733e-01,  1.2741e-01,  1.0000e+00,  6.0293e-01,  7.5029e-01,\n",
            "          9.8174e-01,  2.5507e-01,  4.1035e-02, -6.6219e-02, -9.9978e-01,\n",
            "         -9.0295e-01, -5.6204e-02,  1.3364e-02, -9.9730e-01,  8.6094e-01,\n",
            "         -9.4821e-01,  6.3321e-02, -7.6576e-02,  9.9954e-01,  9.9656e-01,\n",
            "          4.9989e-02, -9.9517e-01, -9.9727e-01,  7.3371e-01,  7.2513e-02,\n",
            "          6.8405e-02, -1.6511e-02, -1.4586e-02,  6.1535e-03, -9.3553e-03,\n",
            "          8.1313e-01, -2.9853e-01,  4.1594e-02, -5.0757e-01,  9.9959e-01,\n",
            "         -5.5845e-02, -9.4736e-01,  8.5648e-01, -8.6356e-03, -6.2806e-01,\n",
            "         -1.2443e-01,  9.9058e-01,  1.3460e-01, -3.0950e-02,  9.7639e-01,\n",
            "         -9.9642e-01,  7.8457e-01, -9.9787e-01, -1.7686e-01,  9.9100e-01,\n",
            "         -1.0000e+00, -1.5053e-01, -1.0000e+00, -9.5395e-01,  1.3278e-01,\n",
            "          2.4274e-01, -1.6542e-01,  6.9819e-01, -1.0000e+00, -9.9653e-01,\n",
            "         -1.9176e-01, -9.6133e-01, -9.7467e-01,  9.5480e-01, -1.3610e-01,\n",
            "         -1.5433e-01, -2.5300e-02,  1.4837e-01, -5.0090e-02,  3.1695e-01,\n",
            "          9.8820e-01, -1.4346e-01, -4.8103e-02, -1.0000e+00,  9.9120e-01,\n",
            "          1.0714e-02, -8.9387e-02,  9.9999e-01,  7.0539e-02,  1.8166e-01,\n",
            "          2.9440e-02, -9.9991e-01,  2.4552e-02, -8.5059e-02, -9.2481e-01,\n",
            "          9.7765e-01,  5.4490e-02, -1.2764e-01,  5.4571e-02,  5.0730e-02,\n",
            "         -8.5847e-01, -4.5678e-02, -9.9988e-01,  9.9999e-01, -9.9433e-01,\n",
            "         -1.0756e-01,  5.7451e-02, -4.8515e-02,  1.6361e-01,  8.9412e-01,\n",
            "          1.0000e+00, -9.1748e-01, -7.4421e-02,  9.9998e-01,  8.5119e-02,\n",
            "         -1.1678e-01, -9.9978e-01,  3.6882e-02,  4.5757e-01,  5.7909e-02,\n",
            "          9.9999e-01,  6.6554e-02, -1.1898e-01,  9.9813e-01, -1.0000e+00,\n",
            "         -9.5776e-01,  2.2211e-02, -7.3820e-02,  4.3688e-02, -9.9999e-01,\n",
            "         -1.1450e-01, -7.8898e-01,  1.0280e-01, -9.9991e-01,  9.9825e-01,\n",
            "         -1.0000e+00, -1.8800e-02,  9.9970e-01, -7.8127e-01,  9.8986e-01,\n",
            "         -4.8875e-02, -3.4235e-02,  1.2083e-01, -9.9879e-01, -5.3233e-01,\n",
            "         -1.5405e-01,  1.0460e-01, -9.9865e-01, -4.2883e-01, -1.0514e-01,\n",
            "          8.9694e-01, -8.6323e-01, -1.3413e-01,  6.8309e-01, -1.5504e-01,\n",
            "          2.2490e-01, -3.1242e-02,  5.0441e-03, -9.2188e-01,  1.8606e-01,\n",
            "         -2.3407e-01,  3.5037e-01,  2.0355e-01,  2.9893e-03, -8.0696e-02,\n",
            "          9.1120e-01, -9.9999e-01,  8.7568e-02, -9.9881e-01, -5.8919e-02,\n",
            "          1.8275e-02, -1.4757e-01, -4.4836e-02, -1.0020e-01,  5.9288e-02,\n",
            "         -9.9950e-01,  1.0000e+00, -9.9988e-01, -9.9978e-01,  9.9951e-01,\n",
            "          7.0556e-02, -9.9453e-01,  2.1178e-01,  1.2624e-01,  2.4491e-01,\n",
            "          1.1565e-01,  1.4719e-01,  2.0920e-01, -2.9703e-02, -7.7232e-01,\n",
            "          9.9087e-01, -4.8392e-02, -2.4941e-02,  4.2205e-03, -1.4364e-01,\n",
            "         -8.3124e-01,  9.9999e-01,  9.9999e-01,  9.8273e-01, -9.9835e-01,\n",
            "         -3.6427e-02, -2.4544e-02,  9.9965e-01,  2.1108e-01, -7.8995e-02,\n",
            "          9.9926e-01,  8.8698e-01, -1.3045e-01, -3.9854e-02,  2.0471e-01,\n",
            "          5.0027e-02, -4.1883e-02,  1.1036e-01, -5.8837e-01, -9.9982e-01,\n",
            "         -1.0619e-02, -9.9384e-01, -8.2562e-01,  8.8384e-01,  4.4460e-02,\n",
            "          1.0000e+00, -1.7555e-01,  1.6654e-01,  1.0319e-01,  3.9452e-01,\n",
            "         -9.9984e-01, -1.7642e-01, -9.2363e-01, -2.9798e-02, -9.9177e-01,\n",
            "         -9.9984e-01, -3.0092e-02,  1.3029e-01, -9.4677e-01, -5.1698e-03,\n",
            "          9.2495e-02, -9.2492e-01,  4.1662e-01, -9.9988e-01, -4.9678e-01,\n",
            "         -4.7921e-01, -5.4502e-01, -1.3045e-01,  6.7933e-03,  1.8861e-01,\n",
            "          1.0967e-02,  4.6236e-01,  9.9219e-01, -4.7957e-01,  1.3716e-01,\n",
            "         -4.2977e-02, -2.0897e-02, -9.9974e-01, -9.2933e-01, -9.9999e-01,\n",
            "          9.9944e-01, -9.9999e-01,  3.0147e-02,  9.9990e-01,  9.9995e-01,\n",
            "         -6.7743e-02, -9.9959e-01,  9.9971e-01,  8.2880e-02,  9.9999e-01,\n",
            "          1.5162e-01, -9.7902e-01, -9.9892e-01,  4.7292e-02, -4.4367e-02,\n",
            "          1.0000e+00,  9.9068e-03, -5.5324e-01, -1.9996e-03, -3.1264e-02,\n",
            "         -2.8048e-02, -6.2962e-02, -2.0948e-01, -5.6104e-02, -2.9591e-02,\n",
            "          8.6629e-01,  5.3666e-02,  9.9999e-01]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None) kkkkkkkkk\n",
            "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.2737,  0.2068, -0.3899,  ..., -0.0376,  0.2201, -0.1823],\n",
            "         [-0.1411,  0.1605, -0.5171,  ...,  0.3797,  0.4072,  0.1105],\n",
            "         [ 0.0885, -0.2672, -0.0653,  ...,  0.2016,  0.3112, -0.1206],\n",
            "         ...,\n",
            "         [ 0.0335,  0.2699, -0.2777,  ...,  0.2973,  0.0509,  0.0480],\n",
            "         [ 0.3561,  0.2514, -0.5771,  ..., -0.4899,  1.1672, -1.7169],\n",
            "         [ 0.3652,  0.2362, -0.5743,  ..., -0.4842,  1.1724, -1.7097]]]), pooler_output=tensor([[-3.7896e-02,  2.1844e-02,  9.7223e-01, -9.9999e-01,  9.9997e-01,\n",
            "          2.9839e-01,  5.2885e-02,  9.5920e-01, -1.0408e-01, -1.2235e-01,\n",
            "          9.0091e-01,  9.9979e-01,  6.7179e-01, -8.5707e-01,  4.0528e-03,\n",
            "          1.0571e-01,  9.9999e-01, -1.0934e-01, -9.9809e-01, -1.1848e-01,\n",
            "          5.7033e-02, -9.6040e-01, -4.1009e-02,  8.8588e-01, -4.8598e-02,\n",
            "         -4.8603e-03,  9.9972e-01,  9.9747e-01, -4.1304e-03,  1.4641e-02,\n",
            "         -2.6993e-02, -9.9999e-01,  9.9523e-01, -9.9987e-01,  2.7572e-02,\n",
            "         -8.9123e-02,  3.8886e-02,  9.0082e-04,  9.1572e-01, -9.9034e-01,\n",
            "         -9.2402e-02, -8.5232e-01,  5.6122e-03,  5.0350e-03,  9.8675e-01,\n",
            "          1.2528e-01,  1.1653e-01,  1.2337e-01,  4.2936e-02,  8.4187e-01,\n",
            "          1.0630e-01,  9.9307e-01,  8.8252e-01,  9.9631e-01,  9.9954e-01,\n",
            "          1.8615e-02,  9.9999e-01, -6.3659e-02,  9.5336e-01,  2.6979e-01,\n",
            "          9.9998e-01,  6.6358e-02,  3.2416e-02, -1.6251e-01, -7.8390e-02,\n",
            "         -6.8784e-02, -3.8088e-01, -3.0112e-02,  3.8507e-02,  2.4657e-02,\n",
            "         -7.2487e-02, -7.4325e-02,  9.9849e-01, -9.9963e-01, -5.9302e-02,\n",
            "          3.8278e-03,  6.9116e-02, -9.5148e-01,  9.9927e-01,  9.9977e-01,\n",
            "         -1.1733e-01, -9.9847e-01,  9.9999e-01, -1.4719e-01,  2.4977e-02,\n",
            "         -1.2454e-01,  9.2534e-01, -9.9973e-01, -5.9453e-03, -1.0162e-02,\n",
            "          3.8536e-01, -9.9984e-01, -3.4065e-02, -5.4023e-01,  9.9841e-01,\n",
            "          5.7991e-01, -3.3249e-02, -8.3879e-02, -2.0239e-01, -1.4328e-01,\n",
            "         -4.3347e-02,  9.0157e-01, -7.4274e-01,  7.8902e-01, -5.0794e-01,\n",
            "          5.6799e-02, -1.7301e-01, -2.0629e-01, -1.0233e-01, -1.6482e-01,\n",
            "          4.7821e-02,  1.4944e-02, -1.9204e-01, -2.3209e-02,  9.6432e-01,\n",
            "          7.9624e-01,  9.9998e-01,  9.9416e-01,  5.6921e-02,  9.9839e-01,\n",
            "         -1.5957e-01,  9.5034e-01,  9.9965e-01,  9.4976e-02, -9.2600e-02,\n",
            "         -1.1207e-02,  3.7076e-02,  9.9442e-01,  1.8270e-01, -1.6846e-01,\n",
            "         -9.0543e-02, -9.9975e-01, -9.8597e-01,  9.9820e-01, -6.0956e-02,\n",
            "          9.9981e-01, -9.9970e-01,  1.5483e-01, -9.7323e-01, -3.3103e-02,\n",
            "         -3.5944e-01,  8.4144e-02, -8.6823e-01, -1.0725e-02,  9.9941e-01,\n",
            "         -4.9400e-03, -9.9201e-01, -1.2004e-01, -1.3573e-01, -2.5536e-01,\n",
            "          1.2765e-01,  1.2950e-01, -1.2902e-01,  9.9728e-01,  5.5904e-02,\n",
            "          9.7377e-01,  9.9460e-01,  8.3662e-02,  2.0310e-01,  3.8014e-01,\n",
            "         -1.1799e-01, -9.9927e-01, -4.6331e-02, -9.8413e-01,  9.9261e-01,\n",
            "          9.9977e-01, -1.2335e-03,  9.5626e-01,  9.9961e-01,  7.3301e-02,\n",
            "         -6.0391e-02,  4.0450e-02, -4.6083e-02,  8.5989e-01,  1.3601e-02,\n",
            "         -2.4184e-02,  2.8977e-02, -3.2364e-02, -9.9951e-01, -1.2174e-01,\n",
            "          8.7082e-01, -3.3333e-02,  1.1971e-01, -9.4958e-01, -9.9998e-01,\n",
            "         -6.3714e-02, -9.9872e-01,  2.0604e-01, -6.2592e-03, -2.3998e-02,\n",
            "          5.9567e-02,  9.9942e-01, -9.1322e-01,  8.5398e-02, -9.6999e-02,\n",
            "          1.3082e-01,  9.9709e-01, -4.7795e-02,  9.9943e-01,  8.6760e-03,\n",
            "         -9.9994e-01, -9.9236e-01, -5.1543e-01, -1.5692e-01,  5.2256e-02,\n",
            "         -6.9424e-02,  8.4900e-02, -1.6126e-02, -8.4807e-01, -9.9504e-01,\n",
            "         -9.4289e-01, -5.8174e-02, -2.1445e-02,  9.7974e-02,  9.0471e-02,\n",
            "          5.6981e-01, -2.2741e-03,  3.7700e-02,  3.8167e-02,  9.9877e-01,\n",
            "         -9.9979e-01, -8.5329e-02, -1.8154e-02, -9.9988e-01, -9.9995e-01,\n",
            "          5.9069e-02, -1.2303e-01,  4.3657e-02, -4.5517e-02, -8.8879e-01,\n",
            "          2.6743e-02,  6.6622e-01,  1.0000e+00, -5.0182e-02,  2.0629e-02,\n",
            "         -9.9829e-01,  8.8353e-01, -2.5583e-02, -1.8148e-01,  8.4391e-02,\n",
            "          3.5757e-02,  3.9064e-04,  7.0298e-02, -5.9776e-01, -9.4621e-02,\n",
            "         -6.1478e-02,  3.9731e-02, -1.1829e-01,  9.8350e-02,  4.0629e-01,\n",
            "         -7.8857e-03,  6.5929e-01, -2.6613e-02,  9.9995e-01, -9.8884e-01,\n",
            "          3.7568e-04,  9.8298e-01, -9.9980e-01,  1.2785e-01,  9.0824e-01,\n",
            "          4.8837e-02, -9.9666e-01, -4.1689e-02, -1.5548e-01, -9.9929e-02,\n",
            "         -1.3641e-02,  9.9991e-01, -8.1898e-03,  6.8535e-02, -7.0082e-02,\n",
            "         -9.9672e-01, -2.0222e-02, -4.6362e-03,  9.9996e-01,  8.4508e-01,\n",
            "          1.4430e-01,  1.3240e-01,  5.1572e-02, -9.9999e-01, -9.3206e-01,\n",
            "          2.8435e-01,  9.7539e-01, -1.0000e+00,  1.6433e-02,  9.9912e-01,\n",
            "          9.6720e-01, -6.8747e-02, -9.9889e-01, -1.9212e-01, -9.9973e-01,\n",
            "          2.5415e-02, -7.6315e-02,  1.6600e-02, -4.0135e-02, -1.4121e-01,\n",
            "          4.8236e-02,  9.9922e-01,  9.9687e-01, -1.3572e-01,  1.5252e-01,\n",
            "         -4.5410e-02, -9.9999e-01, -9.9154e-01, -1.4118e-01,  7.9904e-02,\n",
            "         -9.9286e-01,  1.0000e+00, -9.8724e-01,  9.9658e-01,  9.8342e-01,\n",
            "          9.2688e-01,  5.2371e-02, -9.1124e-02, -9.8267e-01, -4.6899e-02,\n",
            "          9.9691e-01,  9.9883e-01, -7.8730e-02,  8.3331e-03,  6.9526e-01,\n",
            "          3.9909e-02,  5.5589e-02, -1.0095e-01,  1.3568e-01,  2.8366e-02,\n",
            "         -4.8527e-02, -1.1019e-01, -5.3417e-01, -9.1730e-01, -3.7466e-02,\n",
            "         -1.5453e-01,  6.0295e-03, -2.9350e-01,  2.8219e-02,  1.6724e-01,\n",
            "         -3.7464e-02,  4.9031e-02, -8.3076e-02, -6.9744e-01,  2.7928e-01,\n",
            "         -3.3888e-02,  6.8153e-01,  7.5360e-02,  9.6862e-01,  1.4605e-01,\n",
            "         -9.9321e-01,  9.9913e-01, -6.8667e-02, -3.6926e-01,  9.4963e-01,\n",
            "          9.9631e-01, -9.9823e-01, -7.5125e-02, -9.0968e-02, -1.9507e-02,\n",
            "          5.9568e-02,  9.9999e-01, -6.8347e-01, -1.2771e-01,  2.5580e-01,\n",
            "         -2.8164e-02,  2.8301e-02, -6.6260e-03,  1.5726e-01, -1.0713e-01,\n",
            "          9.0275e-01, -6.8209e-02,  9.9473e-01, -8.7324e-01, -1.0623e-01,\n",
            "         -2.2164e-02,  3.1596e-01, -5.6771e-02, -1.3274e-01, -4.3082e-01,\n",
            "         -3.4279e-02, -4.9275e-01, -8.7835e-02, -8.8337e-01,  1.4062e-01,\n",
            "          9.8922e-01,  2.4813e-02, -1.5849e-02, -7.2165e-01, -4.8690e-03,\n",
            "          9.9986e-01, -9.9994e-01, -6.5338e-02,  9.9980e-01, -1.0226e-01,\n",
            "          1.9791e-02,  1.7019e-01, -9.4610e-01, -3.5356e-02, -9.6630e-02,\n",
            "         -9.9564e-01, -1.4071e-02,  1.5014e-01, -5.3813e-02,  2.2537e-02,\n",
            "          9.8013e-02, -1.6294e-01,  2.6568e-01,  1.4380e-02, -1.7827e-02,\n",
            "          1.3090e-01, -1.1532e-01,  1.1423e-01,  4.4794e-04,  8.6942e-02,\n",
            "         -1.5098e-02, -5.5535e-02, -7.9407e-03,  5.3260e-02,  2.0635e-01,\n",
            "          9.9055e-01,  6.2916e-02, -9.9891e-01,  9.2465e-01, -7.9985e-02,\n",
            "         -9.9358e-01, -3.6621e-02, -9.9859e-01,  9.9999e-01,  9.9524e-01,\n",
            "          9.0536e-01,  9.4436e-01, -9.9829e-01, -9.9705e-01,  2.7936e-01,\n",
            "         -4.8893e-02, -2.2616e-02, -2.3517e-02,  9.2036e-01, -3.1079e-03,\n",
            "          1.4276e-01, -3.7542e-02, -6.6104e-02,  2.1153e-01,  9.4929e-01,\n",
            "         -7.0901e-01, -9.9936e-01, -8.5044e-02,  2.9862e-01,  9.0432e-01,\n",
            "         -6.1393e-01, -9.4944e-02,  7.3101e-01, -5.9095e-02, -5.4072e-02,\n",
            "         -6.1209e-02, -1.7148e-03, -9.0764e-03, -9.6576e-01,  7.4516e-02,\n",
            "         -9.9541e-02, -4.3307e-02, -2.0542e-01,  4.2277e-02,  9.1579e-01,\n",
            "         -9.6707e-01,  1.0423e-01, -8.1509e-02, -3.5912e-01, -6.8763e-01,\n",
            "         -8.3045e-01, -2.2866e-01, -8.9508e-01,  1.0633e-01,  6.9417e-02,\n",
            "         -9.9889e-01,  1.3989e-02,  8.7559e-01,  9.8842e-01,  9.9897e-01,\n",
            "         -4.4515e-02, -5.6636e-02,  1.2136e-01,  1.3878e-02, -9.9871e-01,\n",
            "         -2.5100e-01,  1.6262e-01,  2.7124e-02,  9.6941e-02,  1.2410e-01,\n",
            "          9.2851e-02,  8.5329e-01, -9.9588e-01,  9.5533e-01, -3.8561e-02,\n",
            "         -1.2576e-01, -5.5833e-03, -1.3413e-01,  4.9803e-02,  7.4940e-02,\n",
            "         -9.9935e-01,  1.3550e-02,  1.0000e+00,  9.4593e-01,  9.6585e-01,\n",
            "          3.2265e-01, -8.7399e-01,  1.2235e-01, -1.4006e-01, -9.9138e-01,\n",
            "         -9.9592e-01, -8.3063e-02,  3.9518e-02, -9.9958e-01,  9.7498e-01,\n",
            "         -9.9455e-01, -6.7559e-02, -3.8749e-02,  9.8684e-01,  9.9922e-01,\n",
            "          1.8696e-02, -9.9931e-01, -9.9941e-01,  2.7507e-01, -5.9854e-02,\n",
            "          1.4655e-01,  6.4964e-03, -9.7520e-02, -5.3609e-02,  5.4072e-02,\n",
            "          9.6148e-01, -1.1474e-01,  2.9078e-02,  8.1563e-01,  9.9987e-01,\n",
            "          4.6355e-02, -9.9350e-01, -4.7976e-01, -7.9655e-02, -7.8398e-01,\n",
            "         -1.1331e-01,  9.9667e-01,  7.0724e-02,  9.3768e-01,  9.9792e-01,\n",
            "         -9.9911e-01,  9.7056e-01, -9.9952e-01,  9.0965e-01,  9.9857e-01,\n",
            "         -9.9999e-01, -7.1033e-02, -1.0000e+00, -2.9669e-01,  1.4057e-01,\n",
            "          1.8153e-01, -1.9512e-01,  8.5925e-01, -1.0000e+00, -9.9944e-01,\n",
            "         -9.3373e-02,  2.1923e-01, -3.4932e-01,  4.4315e-01,  1.2105e-01,\n",
            "          6.7125e-02,  2.8070e-02,  1.2073e-01, -3.8041e-02, -7.4475e-01,\n",
            "          9.9925e-01, -1.0262e-01, -1.5028e-01, -9.9999e-01,  9.9520e-01,\n",
            "         -7.5203e-02, -3.9539e-02,  9.9999e-01,  1.9686e-02,  1.9675e-01,\n",
            "         -7.7194e-02, -9.9996e-01, -1.9874e-02, -6.3078e-02, -9.7885e-01,\n",
            "          7.3406e-01, -1.1400e-01,  1.9249e-02,  5.8937e-02, -3.5044e-02,\n",
            "         -9.7253e-01, -2.9008e-02, -9.9993e-01,  9.9996e-01, -7.5889e-01,\n",
            "         -1.1802e-02,  3.6157e-02,  9.5877e-02, -1.1957e-02,  9.8168e-01,\n",
            "          1.0000e+00, -9.9813e-01,  6.9509e-02,  9.9999e-01,  4.7304e-02,\n",
            "          1.2611e-01, -9.9990e-01, -3.1757e-02, -7.9866e-01,  7.1290e-02,\n",
            "          9.9999e-01,  3.2828e-02, -3.5186e-02,  9.9855e-01, -9.9999e-01,\n",
            "         -5.3068e-01, -3.8107e-02, -6.9302e-02,  1.7294e-01, -9.9999e-01,\n",
            "          5.3744e-02, -9.7047e-01,  4.6587e-02, -9.9997e-01,  9.4777e-01,\n",
            "         -1.0000e+00,  1.9513e-03,  9.9989e-01,  4.6446e-02,  9.9843e-01,\n",
            "          2.3638e-02, -5.8660e-02, -1.0131e-02, -9.9974e-01,  7.4267e-01,\n",
            "         -7.1234e-02, -5.1058e-02, -9.7769e-01, -9.5983e-01,  5.3851e-02,\n",
            "          4.0876e-01, -9.7348e-01,  2.6095e-02, -5.4743e-01, -2.9332e-02,\n",
            "          1.4460e-01,  7.0675e-02,  1.5189e-01, -1.3531e-01, -3.5901e-02,\n",
            "         -7.6921e-02,  1.1899e-01,  5.0574e-02, -1.3189e-01, -4.1281e-02,\n",
            "          9.8928e-01, -9.9999e-01,  3.5503e-02, -9.9923e-01, -7.9759e-02,\n",
            "          6.9349e-02, -4.5596e-02, -1.4110e-02, -1.5627e-01,  4.8907e-02,\n",
            "         -9.8944e-01,  1.0000e+00, -9.9996e-01, -9.9992e-01,  9.9987e-01,\n",
            "          9.8138e-02, -8.3033e-01,  1.3670e-01,  7.8618e-02, -2.0471e-02,\n",
            "          6.2743e-02,  1.0767e-01,  8.6240e-03,  3.1403e-02, -9.7157e-01,\n",
            "          9.2906e-01, -4.3167e-02, -5.2715e-02, -1.0134e-01,  5.3402e-02,\n",
            "         -9.9724e-01,  9.9999e-01,  9.9999e-01,  9.9791e-01, -9.9968e-01,\n",
            "          7.7841e-02, -3.7203e-02,  9.9992e-01,  1.0301e-01,  4.6630e-02,\n",
            "          9.5719e-01,  9.8051e-01, -4.5164e-02, -8.3078e-01,  1.1203e-01,\n",
            "          5.2130e-02, -5.5745e-03,  1.2660e-01, -9.3977e-01, -9.9373e-01,\n",
            "          3.6813e-02, -9.9893e-01, -9.6932e-01,  9.7208e-01,  4.9147e-02,\n",
            "          1.0000e+00,  3.9186e-02,  1.6212e-01,  1.7428e-02, -6.9482e-01,\n",
            "         -9.9291e-01, -2.0628e-03, -9.8753e-01,  9.5874e-02, -9.9969e-01,\n",
            "         -9.9993e-01,  9.6134e-02,  1.1703e-02, -9.8998e-01,  2.9596e-02,\n",
            "          5.2815e-02, -9.9274e-01, -6.6896e-01, -9.9465e-01,  7.4806e-01,\n",
            "         -7.6413e-01, -9.5461e-01, -1.2658e-01,  7.1145e-01,  2.0427e-01,\n",
            "          1.3613e-02, -7.1400e-01,  8.3940e-01,  8.4686e-01,  1.0520e-01,\n",
            "         -4.3657e-02,  5.6141e-02, -9.8990e-01,  4.5165e-01, -9.9999e-01,\n",
            "          9.9049e-01, -9.9999e-01,  2.1107e-02,  9.9995e-01,  9.9996e-01,\n",
            "         -4.4041e-02, -9.9985e-01,  9.8985e-01,  2.0536e-03,  9.9999e-01,\n",
            "          4.3008e-02, -9.9690e-01, -9.9973e-01,  1.6479e-02, -1.0011e-01,\n",
            "          9.9999e-01,  3.1329e-02,  9.2285e-01,  1.1654e-02,  7.3930e-02,\n",
            "         -1.2004e-01,  5.6977e-03, -1.6830e-01, -2.6079e-02, -4.0727e-02,\n",
            "          9.8219e-01,  3.3816e-02,  9.9999e-01]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None) kkkkkkkkk\n",
            "Answer: \n",
            "Cardiovascular disease is the leading cause of death worldwide\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_zH0OSzE29KQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ff850acf59834223bda0fee009276965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e5c4ec73f05414cb5b023708e20d7ad",
              "IPY_MODEL_9a7c528caf814f2fb4741b0479f81cf5",
              "IPY_MODEL_ffe226bdb82c4d80b6f4ecec0a38db0c"
            ],
            "layout": "IPY_MODEL_79899167bd1a4cdba7aaf9a9af06520e"
          }
        },
        "3e5c4ec73f05414cb5b023708e20d7ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beaf8fa8a874437fbb62a988aa1b8ece",
            "placeholder": "​",
            "style": "IPY_MODEL_7cf9465529244a01981bdeb7d72da02e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "9a7c528caf814f2fb4741b0479f81cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5c55f8b33c6400ea9a68c9e7cebb59e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e17ef05264804bdaaa74043a92005785",
            "value": 2
          }
        },
        "ffe226bdb82c4d80b6f4ecec0a38db0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d2ae718bd9841889b3f42eac4778133",
            "placeholder": "​",
            "style": "IPY_MODEL_7df5ababdaf241c386bc346d03144247",
            "value": " 2/2 [00:01&lt;00:00,  1.81it/s]"
          }
        },
        "79899167bd1a4cdba7aaf9a9af06520e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beaf8fa8a874437fbb62a988aa1b8ece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cf9465529244a01981bdeb7d72da02e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5c55f8b33c6400ea9a68c9e7cebb59e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e17ef05264804bdaaa74043a92005785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d2ae718bd9841889b3f42eac4778133": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7df5ababdaf241c386bc346d03144247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}